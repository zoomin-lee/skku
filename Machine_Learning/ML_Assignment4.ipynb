{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_Assignment4_2017310695_이주민.ipynb","provenance":[{"file_id":"17I72Z8JbmfMZDsrg8PrvB9ZW6fEf8thZ","timestamp":1619415460908}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"_hUuf8W_CKbw"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJ3C6YIVCV_v"},"source":["class LogisticRegression:\n","    def __init__(self, learning_rate=0.00001, n_iters=10000):\n","        self.lr = learning_rate\n","        self.n_iters = n_iters\n","        self.weights = None\n","        self.bias = None\n","\n","    def update(self, dw, db):\n","        \"\"\"\n","        Update self.weights and self.bias using dw and db\n","        \"\"\"\n","        # ==== Problem 1 ====\n","        self.weights -= self.lr * dw\n","        self.bias -= self.lr * db\n","\n","    def compute_gradient(self, X, y, y_predicted):\n","        \"\"\"\n","        Return computed gradients of weight and bias\n","        \"\"\"\n","        n_samples, n_features = X.shape\n","        \n","        dw = None\n","        db = None\n","        # ==== Problem 2 ====\n","        dw = 1/n_samples * np.sum(np.dot((-y + y_predicted).reshape(1, n_samples), X), axis = 0)\n","        db = 1/n_samples * np.sum((-y + y_predicted))       \n","        return dw, db\n","    \n","    def _sigmoid(self, x):\n","        \"\"\"\n","        Compute sigmoid function\n","        \"\"\"\n","        sig = None\n","        # ==== Problem 3 ====\n","        sig = 1 / ( 1 + np.exp(-x) )\n","        return sig\n","    \n","    def get_y_predicted(self, X):\n","        \"\"\"\n","        Build linear model using Numpy\n","        \"\"\"\n","        linear_model = None\n","        # ==== Problem 4 ====\n","        linear_model = np.dot(X, self.weights) + self.bias\n","        return self._sigmoid(linear_model)\n","\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","\n","        self.weights = np.zeros(n_features)\n","        self.bias = 0\n","\n","        for _ in range(self.n_iters):\n","            y_predicted = self.get_y_predicted(X)\n","            dw, db = self.compute_gradient(X, y, y_predicted)\n","            self.update(dw,db)\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Return a list of predicted class\n","        => 0 if prediction score < 0.5 else 1\n","        \"\"\"\n","        y_predicted = self.get_y_predicted(X)\n","        y_predicted_cls = None\n","        # ==== Problem 5 ====\n","        y_predicted[y_predicted<0.5] = 0\n","        y_predicted[y_predicted>=0.5] = 1\n","        y_predicted_cls = y_predicted\n","        return np.array(y_predicted_cls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"apH1DNmIICPd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619534255196,"user_tz":-540,"elapsed":1803,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}},"outputId":"8e58710c-7fa4-48f6-fcc2-5dc82e1db409"},"source":["# Test your algorithm\n","\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","dataset = load_breast_cancer()\n","X = dataset.data\n","y = dataset.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","logistic_regression = LogisticRegression()\n","logistic_regression.fit(X_train, y_train)\n","y_pred = logistic_regression.predict(X_test)\n","print(accuracy_score(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9736842105263158\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VwIibrWywDW8"},"source":[""],"execution_count":null,"outputs":[]}]}